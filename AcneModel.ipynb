{"cells":[{"cell_type":"markdown","metadata":{"id":"yevcgC5LSrVy","cell_id":"9109be45e22048e6a77f738c06b4e071","deepnote_cell_type":"markdown"},"source":"## Environment Setup\n","block_group":"d684d1f994f44ec6b387fd4db140f812"},{"cell_type":"code","metadata":{"id":"4p9vmfA7GnGc","colab":{"background_save":true},"outputId":"1ba7f820-1103-44c4-aeea-395b5965cce7","cell_id":"b71a12a6463d4a82a101bf17f6f12093","deepnote_cell_type":"code"},"source":"from google.colab import drive\ndrive.mount('/content/drive')","block_group":"c853de925fa94b10a491dfda87a36c35","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"Mounted at /content/drive\n"}],"outputs_reference":"dbtable:cell_outputs/5cf08acf-0a4e-40dc-a8c7-503ae35dd95e","content_dependencies":null},{"cell_type":"code","metadata":{"id":"ezT-GE9-THng","colab":{"background_save":true},"cell_id":"4f182d881b0744c1a89878d15c82665e","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout\nfrom PIL import Image\nimport os","block_group":"90c502d1b8bf4ce39c7fff8ccf31ebc2","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"IvuAkL7YjSDF","colab":{"background_save":true},"cell_id":"2cc3815c273c4a998e89ad03161e9b42","deepnote_cell_type":"code"},"source":"# Set up data generators with augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,  # Rotate by ±30°\n    horizontal_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    validation_split=0.2\n)\n\n# Initialize the ImageDataGenerator for testing (usually no augmentation for testing)\ntest_datagen = ImageDataGenerator(rescale=1./255)","block_group":"76908ee5889446f886d9c255f8029390","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"nqvKQ6Usjb7D","colab":{"background_save":true},"cell_id":"c5460745dddd44da831edea6c9b87d6d","deepnote_cell_type":"code"},"source":"# Setup paths\nbase_dir = '/content/drive/My Drive/Acnetify/DATASET_CLEANING/'","block_group":"a0e832b284d745fabc84d568a9509ab3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"89AqqydXjdqT","colab":{"base_uri":"https://localhost:8080/","background_save":true},"outputId":"d801f305-e1eb-4bee-ba37-af959a0ecea1","cell_id":"67f81c7519de4b719ba592f87620f8fb","deepnote_cell_type":"code"},"source":"batch_size = 16\nepochs = 50\nimg_height, img_width = 224, 224\n\n# Creating generators\ntrain_generator = train_datagen.flow_from_directory(\n    base_dir + 'Training_resize',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    # subset='training'  # Set as training data\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    base_dir + 'Val_resize',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    # subset='validation'  # Set as validation data\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    base_dir + 'Test_crop',\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical'\n)","block_group":"60809bec5f8b48ac9d276fabc23cec70","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"Found 3000 images belonging to 5 classes.\nFound 600 images belonging to 5 classes.\nFound 80 images belonging to 4 classes.\n"}],"outputs_reference":"dbtable:cell_outputs/ce423231-eef0-4278-b85a-bc71b9cb7703","content_dependencies":null},{"cell_type":"code","metadata":{"id":"lMpnQ8_PwQUy","colab":{"background_save":true},"outputId":"b397fe9f-bcb1-4a2c-e4a0-625b1d8ddfe1","cell_id":"60a53408301449db9c8b4d2aee63b3cb","deepnote_cell_type":"code"},"source":"from PIL import Image\nimport os\n\ndef check_images(s_dir, ext_list):\n    bad_images = []\n    for fldr in os.listdir(s_dir):\n        sub_folder = os.path.join(s_dir, fldr)\n        if os.path.isdir(sub_folder):\n            for file in os.listdir(sub_folder):\n                file_path = os.path.join(sub_folder, file)\n                if os.path.splitext(file_path)[1].lower() not in ext_list:\n                    continue\n                try:\n                    img = Image.open(file_path)  # open the image file\n                    img.verify()  # verify that it is, in fact, an image\n                except (IOError, SyntaxError) as e:\n                    print('Bad file:', file_path)  # print out the names of corrupt files\n                    bad_images.append(file_path)\n    return bad_images\n\nbad_files = check_images('/content/drive/My Drive/Acnetify/DATASET_CLEANING/Training_awal', ['.jpg', '.jpeg', '.png'])\nprint('Found bad files:', bad_files)","block_group":"c9d7c125c68543018cd8b82bba7012df","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"Found bad files: []\n"}],"outputs_reference":"dbtable:cell_outputs/de374c35-36f0-46b4-9cca-6c1ac8b51401","content_dependencies":null},{"cell_type":"markdown","metadata":{"id":"JbYqQ3djj18w","cell_id":"fb654522b4c8420582a976b136e8bc7a","deepnote_cell_type":"markdown"},"source":"## Model Building","block_group":"700d535aec30479fa149ee6538389a69"},{"cell_type":"code","metadata":{"id":"dW2JQbgTeAG4","colab":{"background_save":true},"cell_id":"3d07818469374531b26023e52336b98e","deepnote_cell_type":"code"},"source":"def ModelNet(input_shape=(224, 224, 3), num_classes=5):\n    X_input = Input(input_shape)\n\n    # Conv Block 1\n    X = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(X_input)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n\n    # Conv Block 2\n    X = Conv2D(48, (3, 3), strides=(2, 2), padding='same')(X)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n\n    # Conv Block 3\n    X = Conv2D(32, (3, 3), padding='same')(X)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n\n    # Conv Block 4\n    X = Conv2D(16, (3, 3), padding='same')(X)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n\n    # Top Layers\n    X = Flatten()(X)\n    X = Dense(512, activation='relu')(X)\n    X = Dense(256, activation='relu')(X)\n    X = Dense(128, activation='relu')(X)\n    X = Dense(num_classes, activation='softmax')(X)\n\n    model = Model(inputs=X_input, outputs=X, name='ModelNet')\n\n    return model\n","block_group":"cfdb0c72bebb4d8da226bdf2721c716e","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"tgZSg7HwFeDy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb646c56-06e8-4ee6-9b35-16d587802436","cell_id":"ca2f9bbb6ad945faa7aca6678e7d3931","deepnote_cell_type":"code"},"source":"model = ModelNet(input_shape=(224, 224, 3), num_classes=5)\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=epochs,\n          validation_data=validation_generator, validation_steps=validation_generator.samples // batch_size)","block_group":"c90edb4ae8ac45158ac5d517f2b0c4c0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/50\n 31/187 [===>..........................] - ETA: 15:20 - loss: 1.6205 - accuracy: 0.2903"}],"outputs_reference":"dbtable:cell_outputs/10ec2f43-56a9-4a73-8b66-089ae67989a5","content_dependencies":null},{"cell_type":"code","metadata":{"id":"IFSu-lomlzXF","cell_id":"93a5dbcdf5d24d058f93a203437c2791","deepnote_cell_type":"code"},"source":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(len(acc))  # Use the length of accuracy array\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.tight_layout()  # Adjust the spacing between subplots\nplt.show()","block_group":"964df1257e4541429351daae441ecf8c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"FbGUKFiJPM4J","cell_id":"2729fb97cf0c4352b1222ba4c30c26c0","deepnote_cell_type":"code"},"source":"import numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n\n# Path untuk data pengujian\ntest_dir = '/content/drive/My Drive/Acnetify/DATASET_CLEANING/'\n\n# Membuat objek ImageDataGenerator untuk data pengujian\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)\n\n# Evaluasi model menggunakan data pengujian\ntest_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\nprint(f'Test Loss: {test_loss}')\nprint(f'Test Accuracy: {test_accuracy}')\n\n# Prediksi menggunakan data pengujian\npredictions = model.predict(test_generator, steps=len(test_generator))\npredicted_classes = np.argmax(predictions, axis=1)\n\n# Menampilkan beberapa prediksi secara acak\nrandom_indices = np.random.choice(len(predicted_classes), size=15, replace=False)\nfor i, idx in enumerate(random_indices):\n    print(f'Image {i+1}: Predicted class - {predicted_classes[idx]}, True class - {test_generator.classes[idx]}')\n\n# Menghitung confusion matrix\nconf_matrix = confusion_matrix(test_generator.classes, predicted_classes)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Menghitung dan mencetak classification report\nclass_names = list(test_generator.class_indices.keys())\nreport = classification_report(test_generator.classes, predicted_classes, target_names=class_names)\nprint(\"Classification Report:\")\nprint(report)\n\n# Menghitung dan mencetak accuracy score\naccuracy = accuracy_score(test_generator.classes, predicted_classes)\nprint(f\"Accuracy: {accuracy}\")\n\n# Menghitung dan mencetak F1 score\nf1 = f1_score(test_generator.classes, predicted_classes, average='weighted')\nprint(f\"F1 Score: {f1}\")","block_group":"eb6afc09fb984dfba8fabf26067ec7a7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"id":"BHfrhvYnPTlT","cell_id":"24f12878821d49edb60c34b44febf12d","deepnote_cell_type":"code"},"source":"","block_group":"9e38a73a42db4aaab674b073061ae6bf","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=7bff57b2-cd1b-4d31-87b2-4f5483361437' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"3c04fe4df24d41628c391bd6a76ab1dd","deepnote_execution_queue":[]}}